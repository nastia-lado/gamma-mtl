{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power spectrum for 1 sec pre- and 1 sec post- stimulus\n",
    "not used in the final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter DataJoint username:  root\n",
      "Please enter DataJoint password:  ···············\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting root@localhost:3306\n",
      "Epiphyte Setup\n"
     ]
    }
   ],
   "source": [
    "import database.neuralynx_extract.combinato_tools as ct\n",
    "import database.neuralynx_extract.nlxio as nlxio\n",
    "\n",
    "import preprocessing.data_preprocessing.refractor_utils as ru\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datajoint as dj\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "import neurokit as nk\n",
    "import neurokit2 as nk2\n",
    "\n",
    "from statsmodels.stats import multitest\n",
    "from numpy.random import RandomState\n",
    "from permute.core import one_sample, two_sample\n",
    "from netneurotools import stats\n",
    "import mne\n",
    "\n",
    "# Local application imports \n",
    "from database.db_setup import *\n",
    "import preprocessing.data_preprocessing.binning as binning\n",
    "import preprocessing.data_preprocessing.create_vectors_from_time_points as create\n",
    "\n",
    "import utils.helper_func as hf\n",
    "import utils.preprocessing as preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = '/home/anastasia/epiphyte/anastasia/output'\n",
    "\n",
    "patient_id = 53\n",
    "session_nr = 1\n",
    "\n",
    "df_patient_info = pd.read_csv(f'{top_dir}/{patient_id}_channel_info.csv')\n",
    "\n",
    "fs = 32768\n",
    "#The resulting sample rate is up / down times the original sample rate.\n",
    "up = 1\n",
    "down=32\n",
    "fs_downs = (up/down)*fs\n",
    "dt = 1/fs_downs      # sampling period/time/interval or time resolution, often denoted as T\n",
    "\n",
    "times = np.linspace(-500, 1000, num = int(1.5*fs_downs))\n",
    "time_zero_idx = np.where(times == hf.find_nearest(times, 0))[0][0]\n",
    "\n",
    "df_stim_info = pd.DataFrame(ScreeningAnnotation())\n",
    "df_stim_info = df_stim_info.loc[df_stim_info['patient_id'] == patient_id]\n",
    "df_stim_info = df_stim_info.reset_index()\n",
    "df_stim_info.to_csv(f'{top_dir}/{patient_id}_df_stim_info.csv')\n",
    "#get relation of filename to stim name\n",
    "df = df_stim_info.drop_duplicates(subset=['filename'])\n",
    "df.to_csv(f'{top_dir}/df_stim_filename.csv')\n",
    "\n",
    "#get 500 events\n",
    "df_movie = pd.DataFrame(MovieAnnotation())\n",
    "df_movie.to_csv(f'{top_dir}/df_movie_annotaion.csv')\n",
    "\n",
    "all_stim = np.unique(df_stim_info['stim_id'])\n",
    "\n",
    "downs_dir = f'{top_dir}/01-preprocessed_{patient_id}/downsampled'\n",
    "timestamps_downs = np.load(f'{downs_dir}/{patient_id}_timestamps_downs.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power spectra of the entire recording (~ 2 hours?) for each electrode separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot each channel separately\n",
    "for i in range(len(df_patient_info['channel_name'])):\n",
    "    ch = df_patient_info.loc[i,'channel_name']\n",
    "    ch_site = df_patient_info.loc[i,'recording_site']\n",
    "    \n",
    "    my_file = Path(f'{downs_dir}/{patient_id}_channel-{ch}_downsampled_data.npy')\n",
    "    downsampled_data = np.load(my_file)\n",
    "    downsampled_data = preprocessing.notch_filter(downsampled_data, patient_id, ch)\n",
    "    \n",
    "    \n",
    "    f, welchpow = scipy.signal.welch(downsampled_data,fs=fs_downs, nperseg=2000, noverlap=500)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(15, 5))\n",
    "    fig.suptitle(f'Channel: {ch}, recording site: {ch_site}')\n",
    "\n",
    "    ax1.semilogy(f,welchpow)\n",
    "    ax1.set_xlabel('frequency [Hz]')\n",
    "    ax1.set_ylabel('Power [log]')\n",
    "\n",
    "    ax2.loglog(f,welchpow)\n",
    "    ax2.set_title('loglog scale')\n",
    "    ax2.set_xlabel('frequency [Hz, log scale]')\n",
    "    ax2.set_ylabel('Power [log]')\n",
    "    \n",
    "    fig.savefig(f'{top_dir}/03-stationary_FFT/entire_channel/{ch}_{ch_site}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "prng = RandomState(50)\n",
    "n_permutations = 5000\n",
    "method = 'fdr_bh'\n",
    "columns = ['channel_name', 'channel_location', 'stim_index', 'stim_name', 'paradigm', 'corr_results', 'locations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = f'{top_dir}/03-stationary_FFT/post_post_comparison'\n",
    "hf.create_folder_structure(parent_dir, df_patient_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power spectrum computed separately for the epochs (2s) during pre-screening and post-screening.\n",
    "I divided each epoch into the pre-stimulus (1s) and post-stimulus (1s) parts.\n",
    "\n",
    "Each stimulus was presented 10 times. I computed the power spectrum for each presentation separately, then averaged the 10 resulting power spectra and plotted the averaged spectrum.\n",
    "\n",
    "Then i computed t-test for non-averaged power spectra pre- and post-stimulus presentation.\n",
    "Vertical lines on the plots indicate the frequencies at which the results were significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.linspace(-1000, 1000, num = 2001)\n",
    "list_strings_1 = []\n",
    "list_strings_2 = []\n",
    "\n",
    "for i in range(len(df_patient_info['channel_name'])):\n",
    "    ch = df_patient_info.loc[i,'channel_name']\n",
    "    ch_site = df_patient_info.loc[i,'recording_site']\n",
    "    epochs = np.load(f'{top_dir}/02-epochs/broadband_2_sec/{patient_id}_epochs_channel-{ch}.npy')\n",
    "\n",
    "    for st in all_stim:\n",
    "        pre = df_stim_info.loc[(df_stim_info['position']=='pre') & (df_stim_info['stim_id']==st)]\n",
    "        pre = pre.reset_index(drop=True)\n",
    "        post = df_stim_info.loc[(df_stim_info['position']=='post') & (df_stim_info['stim_id']==st)]\n",
    "        pre_index = np.array(pre['stim_index'])\n",
    "        post_index = np.array(post['stim_index'])\n",
    "\n",
    "        pre_pwr_array_1 = []\n",
    "        pre_pwr_array_2 = []\n",
    "        post_pwr_array_1 = []\n",
    "        post_pwr_array_2 = []\n",
    "        pre_epoch_1 = np.zeros((10,1000))\n",
    "        pre_epoch_2 = np.zeros((10,1000))\n",
    "        post_epoch_1 = np.zeros((10,1000))\n",
    "        post_epoch_2 = np.zeros((10,1000))\n",
    "\n",
    "        for i in range(len(pre_index)):\n",
    "            pre_epoch = epochs[pre_index[i], :]\n",
    "            post_epoch = epochs[post_index[i], :]\n",
    "\n",
    "            pre_epoch_1[i,:] = pre_epoch[0:1000]\n",
    "            pre_epoch_2[i,:] = pre_epoch[1001:2001]\n",
    "\n",
    "            post_epoch_1[i,:] = post_epoch[0:1000]\n",
    "            post_epoch_2[i,:] = post_epoch[1001:2001]\n",
    "\n",
    "        N = len(pre_epoch_1[0,:])\n",
    "\n",
    "        #check computation here\n",
    "        pwr_pre_1 = np.abs(scipy.fftpack.fft(pre_epoch_1)/N)**2\n",
    "        pwr_pre_2 = np.abs(scipy.fftpack.fft(pre_epoch_2)/N)**2\n",
    "        pwr_post_1 = np.abs(scipy.fftpack.fft(post_epoch_1)/N)**2\n",
    "        pwr_post_2 = np.abs(scipy.fftpack.fft(post_epoch_2)/N)**2\n",
    "\n",
    "        freqs = scipy.fftpack.fftfreq(N) * fs_downs\n",
    "        freqs = freqs[0:N//2]\n",
    "\n",
    "        pwr_pre_1 = pwr_pre_1[:, 0:N//2]\n",
    "        pwr_pre_2 = pwr_pre_2[:, 0:N//2]\n",
    "        pwr_post_1 = pwr_post_1[:, 0:N//2]\n",
    "        pwr_post_2 = pwr_post_2[:, 0:N//2]\n",
    "\n",
    "        pre_pwr_array_1 = np.array(pre_pwr_array_1)\n",
    "        pre_pwr_array_2 = np.array(pre_pwr_array_2)\n",
    "        post_pwr_array_1 = np.array(post_pwr_array_1)\n",
    "        post_pwr_array_2 = np.array(post_pwr_array_2)\n",
    "\n",
    "        current_stim_index = pre.loc[0,'stim_index']\n",
    "        current_stim_name = pre.loc[0,'stim_name']\n",
    "        current_stim_paradigm = pre.loc[0,'paradigm']\n",
    "\n",
    "        #t-test\n",
    "        t_val, p_values = scipy.stats.ttest_rel(pwr_pre_1, pwr_pre_2, 0)\n",
    "        output = multitest.multipletests(p_values, alpha=alpha, method=method)\n",
    "        reject = output[0]\n",
    "        pval_corrected = output[1]\n",
    "        if True in reject:\n",
    "            string = f'{method}-corrected significant results'\n",
    "            #print(string)\n",
    "            a1 = np.where(pval_corrected <= 0.05)[0]\n",
    "            #print(a1)\n",
    "            list_strings_1.append((ch, ch_site, current_stim_index, current_stim_name, current_stim_paradigm, string, a1))\n",
    "        else:\n",
    "            string = f\"no {method}-corrected significant results\"\n",
    "            #list_strings.append(string)\n",
    "            #print(f\"no {method}-corrected significant results\")\n",
    "            a1=[]\n",
    "\n",
    "        #t-test\n",
    "        t_val, p_values = scipy.stats.ttest_rel(pwr_post_1, pwr_post_2, 0)\n",
    "        output = multitest.multipletests(p_values, alpha=alpha, method=method)\n",
    "        reject = output[0]\n",
    "        pval_corrected = output[1]\n",
    "        if True in reject:\n",
    "            string = f'{method}-corrected significant results'\n",
    "            #print(string)\n",
    "            a2 = np.where(pval_corrected <= 0.05)[0]\n",
    "            #print(a2)\n",
    "            list_strings_2.append((ch, ch_site, current_stim_index, current_stim_name, current_stim_paradigm, string, a2))\n",
    "        else:\n",
    "            string = f\"no {method}-corrected significant results\"\n",
    "            #list_strings.append(string)\n",
    "            #print(f\"no {method}-corrected significant results\")\n",
    "            a2=[]\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(20, 5))\n",
    "        title = f'channel: {ch}, recording_site: {ch_site}, stim_index:{current_stim_index}, stim_name:{current_stim_name}, paradigm:{current_stim_paradigm}'\n",
    "        fig.suptitle(title)\n",
    "\n",
    "        ax1.loglog(freqs,np.mean(pwr_pre_1, axis=0), label='pre')\n",
    "        ax1.loglog(freqs,np.mean(pwr_pre_2, axis=0), label='post')\n",
    "        ax1.set_title('pre movie')\n",
    "        ax1.set_xlabel('Frequency [log]')\n",
    "        ax1.set_ylabel('Power [log]')\n",
    "        for k in range(int(len(a1))):\n",
    "            plt.axvline(a1[k], color='k')\n",
    "        ax1.legend()\n",
    "\n",
    "        ax2.loglog(freqs,np.mean(pwr_post_1, axis=0), label='pre')\n",
    "        ax2.loglog(freqs,np.mean(pwr_post_2, axis=0), label='post')\n",
    "        ax2.set_title('post movie')\n",
    "        ax2.set_xlabel('Frequency [log]')\n",
    "        ax2.set_ylabel('Power [log]')\n",
    "        for k in range(int(len(a2))):\n",
    "            plt.axvline(a2[k], color='k')        \n",
    "        ax2.legend()\n",
    "        \n",
    "        fig.savefig(f'{top_dir}/03-stationary_FFT/pre_post_comparison/{ch}_{ch_site}/{title}.png')\n",
    "        plt.close()\n",
    "\n",
    "        #plt.show()\n",
    "        \n",
    "df_pre_movie = pd.DataFrame(list_strings_1, columns=columns)\n",
    "df_post_movie = pd.DataFrame(list_strings_2, columns=columns)\n",
    "\n",
    "df_pre_movie.to_csv(f'{top_dir}/03-stationary_FFT/pre-movie.csv')\n",
    "df_post_movie.to_csv(f'{top_dir}/03-stationary_FFT/post-movie.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#post/post comparison\n",
    "times = np.linspace(-1000, 1000, num = 2001)\n",
    "list_strings_1 = []\n",
    "\n",
    "for i in range(len(df_patient_info['channel_name'])):\n",
    "    ch = df_patient_info.loc[i,'channel_name']\n",
    "    ch_site = df_patient_info.loc[i,'recording_site']\n",
    "    epochs = np.load(f'{top_dir}/02-epochs/broadband_2_sec/{patient_id}_epochs_channel-{ch}.npy')\n",
    "\n",
    "    for st in all_stim:\n",
    "        pre = df_stim_info.loc[(df_stim_info['position']=='pre') & (df_stim_info['stim_id']==st)]\n",
    "        pre = pre.reset_index(drop=True)\n",
    "        post = df_stim_info.loc[(df_stim_info['position']=='post') & (df_stim_info['stim_id']==st)]\n",
    "        pre_index = np.array(pre['stim_index'])\n",
    "        post_index = np.array(post['stim_index'])\n",
    "\n",
    "        pre_pwr_array_1 = []\n",
    "        pre_pwr_array_2 = []\n",
    "        post_pwr_array_1 = []\n",
    "        post_pwr_array_2 = []\n",
    "        \n",
    "        pre_epoch_1 = np.zeros((10,1000))\n",
    "        pre_epoch_2 = np.zeros((10,1000))\n",
    "        post_epoch_1 = np.zeros((10,1000))\n",
    "        post_epoch_2 = np.zeros((10,1000))\n",
    "\n",
    "        for i in range(len(pre_index)):\n",
    "            pre_epoch = epochs[pre_index[i], :]\n",
    "            post_epoch = epochs[post_index[i], :]\n",
    "\n",
    "            #pre_epoch_1[i,:] = pre_epoch[0:1000]\n",
    "            pre_epoch_2[i,:] = pre_epoch[1001:2001]\n",
    "\n",
    "            #post_epoch_1[i,:] = post_epoch[0:1000]\n",
    "            post_epoch_2[i,:] = post_epoch[1001:2001]\n",
    "\n",
    "        N = len(pre_epoch_2[0,:])\n",
    "        \n",
    "        #pwr_pre_1 = np.abs(scipy.fftpack.fft(pre_epoch_1)/N)**2\n",
    "        pwr_pre_2 = np.abs(scipy.fftpack.fft(pre_epoch_2)/N)**2\n",
    "        #pwr_post_1 = np.abs(scipy.fftpack.fft(post_epoch_1)/N)**2\n",
    "        pwr_post_2 = np.abs(scipy.fftpack.fft(post_epoch_2)/N)**2\n",
    "\n",
    "        freqs = scipy.fftpack.fftfreq(N) * fs_downs\n",
    "        freqs = freqs[0:N//2]\n",
    "\n",
    "        #pwr_pre_1 = pwr_pre_1[:, 0:N//2]\n",
    "        pwr_pre_2 = pwr_pre_2[:, 0:N//2]\n",
    "        #pwr_post_1 = pwr_post_1[:, 0:N//2]\n",
    "        pwr_post_2 = pwr_post_2[:, 0:N//2]\n",
    "\n",
    "        pre_pwr_array_1 = np.array(pre_pwr_array_1)\n",
    "        pre_pwr_array_2 = np.array(pre_pwr_array_2)\n",
    "        post_pwr_array_1 = np.array(post_pwr_array_1)\n",
    "        post_pwr_array_2 = np.array(post_pwr_array_2)\n",
    "        \n",
    "        current_stim_index = pre.loc[0,'stim_index']\n",
    "        current_stim_name = pre.loc[0,'stim_name']\n",
    "        current_stim_paradigm = pre.loc[0,'paradigm']        \n",
    "\n",
    "        #t-test\n",
    "        t_val, p_values = scipy.stats.ttest_rel(pwr_pre_2, pwr_post_2, 0)\n",
    "        output = multitest.multipletests(p_values, alpha=alpha, method=method)\n",
    "        reject = output[0]\n",
    "        pval_corrected = output[1]\n",
    "        if True in reject:\n",
    "            string = f'{method}-corrected significant results'\n",
    "            #list_strings.append(string)\n",
    "            #print(string)\n",
    "            a1 = np.where(pval_corrected <= 0.05)[0]\n",
    "            #print(a1)\n",
    "            list_strings_1.append((ch, ch_site, current_stim_index, current_stim_name, current_stim_paradigm, string, a1))\n",
    "        else:\n",
    "            string = f'no {method}-corrected significant results'\n",
    "            #list_strings.append(string)\n",
    "            #print(string)\n",
    "            a1=[]\n",
    "        \n",
    "        plt.rcParams['figure.figsize'] = (20,3)\n",
    "        plt.loglog(freqs,np.mean(pwr_pre_2, axis=0), label='pre_movie')\n",
    "        plt.loglog(freqs,np.mean(pwr_post_2, axis=0), label='post_movie')\n",
    "        for k in range(int(len(a1))):\n",
    "            plt.axvline(a1[k], color='k')\n",
    "        title = f'channel: {ch}, recording_site: {ch_site}, stim_index:{current_stim_index}, stim_name:{current_stim_name}, paradigm:{current_stim_paradigm}'\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Frequency')\n",
    "        plt.ylabel('Power')\n",
    "        plt.legend()\n",
    "        \n",
    "        #plt.show()\n",
    "        \n",
    "        plt.savefig(f'{top_dir}/03-stationary_FFT/post_post_comparison/{ch}_{ch_site}/{title}.png')\n",
    "        plt.close()\n",
    "        \n",
    "        del a1\n",
    "\n",
    "df_post_movie = pd.DataFrame(list_strings_1, columns=columns)\n",
    "df_post_movie.to_csv(f'{top_dir}/03-stationary_FFT/post_post_comparison.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
